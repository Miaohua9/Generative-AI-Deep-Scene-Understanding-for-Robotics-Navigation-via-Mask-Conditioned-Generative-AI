<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Quality-Driven and Diversity-Aware Sample Expansion for Robust Marine Obstacle Segmentation</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Quality-Driven and Diversity-Aware Sample Expansion for Robust Marine Obstacle Segmentation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Miaohua Zhang, Mohammad Ali Armin, Xuesong Li, Sisi Liang, Lars Petersson, Changming Sun, David Ahmedt-Aristizabal, Zeeshan Hayder,</span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Data61, CSIRO<br>WACV2026, Tucson, Arizona, USA</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2512.13970" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


 <!-- Result Images with Captions -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered"></h2>

    <div class="content">
      <figure>
        <img src="static/images/Generative_img2.png" alt="x ">
        <figcaption class="has-text-centered">
          <strong>Figure 1:</strong> (a) Original image and its mask; (b) generated images using a simple prompt; (c) generated images using the proposed style bank and Adaptive Annealed Sampling (AAS) strategy.
        </figcaption>
      </figure>

      <!-- Add more figures here as needed -->
    </div>
  </div>
</section>
  
<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Marine obstacle detection demands robust segmentation under challenging conditions, such as sun glitter, fog, and rapidly changing wave patterns. These factors degrade image quality, while the scarcity and structural repetition
of marine datasets limit the diversity of available training data. Although mask-conditioned diffusion models can synthesize layout-aligned samples, they often produce low-diversity outputs when conditioned on low-entropy masks
and prompts, limiting their utility for improving robustness. In this paper, we propose a quality-driven and diversity-aware sample expansion pipeline that generates training data entirely at inference time, without retraining the diffusion model. The framework combines two key components: (i) a class-aware style bank that constructs high-entropy, semantically grounded prompts, and (ii) an adaptive annealing sampler that perturbs early conditioning, while a
COD-guided proportional controller regulates this perturbation to boost diversity without compromising layout fidelity. Across marine obstacle benchmarks, augmenting training data with these controlled synthetic samples consistently improves segmentation performance across multiple backbones and increases visual variation in rare and
texture-sensitive classes.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


  
<!-- Result Images with Captions -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Quantitative results</h2>

    <div class="content">
      <figure>
        <img src="static/images/table1.png" alt="2D seagrass segmentation">
        <figcaption class="has-text-centered">
          <strong>Table 1:</strong>  Evaluation results across two datasets and different augmentation settings. Reported metrics include water-edge RMSE (px),
water-land detections (%), precision (Pr), recall (Re), true positives (TPr), false positives (FPr), and F1 score.
        </figcaption>
      </figure>

      <!-- Add more figures here as needed -->
    </div>
  </div>
</section>

<!-- Visual Results Carousel -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Qualitative Visualizations</h2>
    <div id="visual-carousel" class="carousel results-carousel">

      <!-- Visual 1 -->
      <div class="item has-text-centered">
        <img src="static/images/result1.png" alt="Visual Result 1"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Figure 2:</strong> Example of augmented images. (a) Original example image and mask; (b) Augmented images. 1st row: generated images
with traditional data augmentation method; 2nd row: Generated images using Default setting of ControlNet ++(simple prompt); 3rd row:
Generated images using proposed AAS method.
        </h2>
      </div>

      <!-- Visual 2 -->
      <div class="item has-text-centered">
        <img src="static/images/result2.png" alt="Visual Result 2"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Figure 3:</strong> Overlayed images from traditional method (1st row), simple prompt (2nd row), and the proposed AAS method (3rd row).
        </h2>
      </div>

    </div>
  </div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{zhang2024efficient,
  title={Quality-Driven and Diversity-Aware Sample Expansion for Robust Marine Obstacle Segmentation},
  author={Miaohua Zhang, Mohammad Ali Armin, Xuesong Li, Sisi Liang, Lars Petersson, Changming Sun, David Ahmedt-Aristizabal, Zeeshan Hayder},
  booktitle={2026 The Winter Conference on Applications of Computer Vision (WACV) Workshop: WVAQ},
  year={2026},
  organization={IEEE}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
